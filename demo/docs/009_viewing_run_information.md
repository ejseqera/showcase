# Run Information

Upon launching a Pipeline, you'll be navigated to the 'Runs' tab which contains all executed workflows. 

The Runs tab contains all previous job executions. Each new or resumed job is given a random name, e.g., "grave_williams". Each row corresponds to a specific job. As a job executes, it can transition through the following states:

- **submitted**: Pending execution
- **running**: Running
- **succeeded**: Completed successfully
- **failed**: Successfully executed, where at least one task failed with a terminate error strategy
- **cancelled**: Stopped forceably during execution
- **unknown**: Indeterminate status


/// details | Click to show animation
    type: example

![Viewing Runs](assets/sp-cloud-view-all-runs.gif)
///

## 1. View the run details for nf-core/rnaseq

The pipeline launched in the [previous step](./005_launching_pipelines.md) will take some time to begin running. In the meantime, we can take a look at a previous successful run to observe the run details.

Click on a previous run to go to the Run Details.

## 2. Run details page

As the pipeline begins to run, you will see the Runs page become populated with the following tabs:

- **Command-line**: The Nextflow command invocation that would be used to run the pipeline. This contains details about the version (through the `-r` flag), and profile, if specified (through the `-profile` flag).

- **Parameters**: Exact set of parameters used in the execution. This is helpful for reproducing results of a previous run.

- **Resolved Nextflow configuration**: The full Nextflow configuration settings used for the run. This includes parameters, but also settings specific to task execution (i.e. memory, CPUs, output directory).

- **Execution Log**: A summarized Nextflow log providing information about the pipeline, and the status of the run.

- **Datasets**: Link to Datasets if any were used in the run.

- **Reports**: View outputs of your pipeline directly in the Platform.


/// details | Click to show animation
    type: example

![View the rnaseq run](assets/sp-cloud-run-info.gif)
///

## 3. View Reports

Most Nextflow pipelines will generate reports or output files which are useful to inspect at the end of the pipeline execution. 

Reports can contain quality control (QC) metrics that would be important to assess the integrity of the results.

For example, for the nf-core/rnaseq pipeline, you can view the MultiQC report generated. MultiQC is helpful reporting tool to generate aggregate statistics and summaries from bioinformatics tools.

![Reports tab](assets/reports-tab.png)

![Reports MultiQC preview](assets/reports-preview.png)

Notice the path to the file will still point to a location on the user's infrastructure, but we are able to more transparently see the contents and download the file, without having to go to the Cloud or a remote filesystem.

### Specifying outputs in Reports

To customize and instruct the Platform on where to find reports generated by the pipeline, the Platform requires a YAML file [tower.yml](https://github.com/nf-core/rnaseq/blob/master/tower.yml) that contains the locations of the generated reports. 

In the nf-core/rnaseq pipeline, the MULTIQC process step generates a MultiQC report file in HTML format.

```yaml
reports:
  multiqc_report.html:
    display: "MultiQC HTML report"
```

## 4. View general information

On the Runs page will be General information about who executed the run, when, the Git hash used and tag, as well as additional details about the compute environment used, and the version of Nextflow.


/// details | Click to show animation
    type: example

![General run information](assets/general-run-details.gif)
///

The 'General' panel displays top-level information about a pipeline run:

- Unique workflow run ID
- Workflow run name
- Timestamp of pipeline start
- Project revision and Git commit ID
- Nextflow session ID
- Username of the launcher
- Work directory path

## 5. View details for a Task

Scroll down the Runs page and you will see:

- The progress of each Process in the pipeline
- Aggregated stats for the Run (i.e. total walltime, CPU hours)
- Workflow metrics (i.e. CPU efficiency, memory efficiency)
- Task details table for every task in the workflow

The task details table can provide further information of every step in the pipeline, what the status of the task is, and metrics for the task.

## 6. Task details window

Select a task in the task table to open the Task details dialog. The dialog has three tabs: About, Execution log and Data Explorer.

**About**

The About tab provides the following information:

1. **Name**: Process name and tag

2. **Command**: Task script, defined in the pipeline process

3. **Status**: Exit code, task status, attempts

4. **Work directory**: Directory where the task was executed

5. **Environment**: Environment variables that were supplied to the task

6. **Execution time**: Metrics for task submission, start, and completion time

7. **Resources requested**: Metrics for the resources requested by the task

8. **Resources used**: Metrics for the resources used by the task


/// details | Click to show animation
    type: example

![Task details window](assets/task-details.gif)
///

**Execution log**

The Execution log tab provides a real-time log of the selected task's execution. Task execution and other logs (such as stdout and stderr) are available for download from here, if still available in your compute environment.

## 7. Task work directory in Data Explorer

If a task fails, a good place to begin troubleshooting is taking a look at the task's work directory.

Nextflow hash-addresses each task of the pipeline and creates unique directories based on these hashes. Instead of navigating through a bucket on the Cloud console or filesystem to find the contents of this directory, we can make use of the 'Data Explorer' tab in the Task window.

The Data Explorer tab allows you to view the log files and output files generated for each task in it's working directory, directly within the Platform.

You can view, download, and retrieve the link for these intermediate files stored in the Cloud from the Explorer tab - making troubleshooting much simpler.


/// details | Click to show animation
    type: example

![Task data explorer](assets/sp-cloud-task-data-explorer.gif)
///

## 8. Resume a Pipeline

Seqera Platform enables you to use Nextflow's resume functionality to resume a workflow run with the same parameters, using the cached results of previously completed tasks and only executing failed and pending tasks.


/// details | Click to show animation
    type: example

![Resuming a run](assets/sp-cloud-resume-a-run.gif)
///

To resume a failed or cancelled run:

- Click on the three dots next to the Run
- Select 'Resume' from the options menu
- Edit the parameters before launch, if desired
- If you have the appropriate permissions, you may edit the compute environment if desired
